{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate read order txt file\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "\n",
    "base_dir =\"/homeL/1sliu/code/SSL_UNet3D/data/CHAOST2/chaos_MR_T2_normalized\"\n",
    "sup_img_re = \"image*.nii.gz\" \n",
    "sup_label_re = \"superpix3d*.nii.gz\" \n",
    "qry_img_re = \"image*.nii.gz\" \n",
    "qry_label_re = \"label*.nii.gz\"\n",
    "\n",
    "sup_img_file = \"sup_img_file.txt\"\n",
    "sup_label_file = \"sup_label_file.txt\"\n",
    "qry_img_file = \"qry_img_file.txt\"\n",
    "qry_label_file = \"qry_label_file.txt\"\n",
    "\n",
    "\n",
    "def getNameList(base_dir,data_re):\n",
    "    data_file_names = []\n",
    "    for file_name in glob.glob(os.path.join(base_dir,data_re)):\n",
    "        data_file_names.append(file_name)\n",
    "    return data_file_names\n",
    "\n",
    "def writeNameFile(lines, base_dir, write_with_file_name=\"None.txt\"):\n",
    "    file_path = os.path.join(base_dir,write_with_file_name)\n",
    "    with open(file_path,'w') as f:\n",
    "        for line in lines:\n",
    "            f.write(line)\n",
    "            f.write('\\n')\n",
    "\n",
    "sup_img_names = getNameList(base_dir, sup_img_re)\n",
    "sup_label_names = getNameList(base_dir, sup_label_re)\n",
    "\n",
    "# shuffle order together\n",
    "c = list(zip(sup_img_names,sup_label_names))\n",
    "random.Random(4).shuffle(c)\n",
    "sup_img_names,sup_label_names = zip(*c) \n",
    "\n",
    "# with original order\n",
    "qry_img_names = getNameList(base_dir, qry_img_re)\n",
    "qry_label_names = getNameList(base_dir, qry_label_re)\n",
    "\n",
    "writeNameFile(sup_img_names,base_dir,write_with_file_name=sup_img_file)\n",
    "writeNameFile(sup_label_names,base_dir,write_with_file_name=sup_label_file)\n",
    "writeNameFile(qry_img_names,base_dir,write_with_file_name=qry_img_file)\n",
    "writeNameFile(qry_label_names,base_dir,write_with_file_name=qry_label_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/fabzhang/ssl/5286ab260b83403fa9716ebb506c0638\n",
      "\n",
      "/homeL/1sliu/anaconda3/envs/unet3d/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Before everythings\n",
    "import comet_ml\n",
    "\n",
    "# Create an experiment with your api key\n",
    "experiment = comet_ml.Experiment(\n",
    "    api_key=\"4e45dKB4oaj3YgKFrQ0MhPld1\",\n",
    "    project_name=\"ssl\",\n",
    ")\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import SimpleITK as sitk\n",
    "import torch.nn as nn\n",
    "from medpy.io import load\n",
    "import torchio as tio\n",
    "import nibabel as nib\n",
    "import numpy\n",
    "from pytorch3dunet.datasets.utils import SliceBuilder \n",
    "\n",
    "\n",
    "\n",
    "def read_text_file(filename):\n",
    "    lines = []\n",
    "    # print(f\"start to read text file:{filename}\")\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file: \n",
    "            # print(f\"line:{line}\")\n",
    "            line = line.strip() #or some other preprocessing\n",
    "            lines.append(line)\n",
    "    # print(f\"length of text file:{len(lines)}\")\n",
    "    return lines\n",
    "\n",
    "def nii_read(filename):\n",
    "    # print(f\"nii_resad:{filename}\")\n",
    "    # voxel_obj =  sitk.ReadImage(filename)\n",
    "    # print(voxel_obj)\n",
    "    # voxel_arr = sitk.GetArrayFromImage(voxel_obj) \n",
    "    # print(voxel_arr.shape)\n",
    "    voxel_arr,voxel_header = load(filename)\n",
    "    voxel_arr = numpy.swapaxes(voxel_arr,0,2)\n",
    "    return voxel_arr\n",
    "########\n",
    "# # test nii_read code\n",
    "# import numpy\n",
    "# import torchio.transforms as transforms\n",
    "# test_data_file = \"./data/CHAOST2/chaos_MR_T2_normalized/image_1.nii.gz\"\n",
    "# vox_arr = nii_read(test_data_file)\n",
    "# print(vox_arr.shape)\n",
    "# swap_ax =numpy.swapaxes(vox_arr,0,2)\n",
    "# cut_depth = swap_ax[:31,:,:]\n",
    "# add_di = cut_depth[None,:]\n",
    "# print(add_di.shape)\n",
    "# result = torch.as_tensor(add_di)\n",
    "# print(result.shape)\n",
    "\n",
    "#########\n",
    "\n",
    "class SSLDataset(Dataset):\n",
    "    def __init__(self, root_dir, sup_file, sup_label_file, qry_file, qry_label_file):\n",
    "        self.root_dir = root_dir\n",
    "        self.sup_file = read_text_file(os.path.join(self.root_dir, sup_file))\n",
    "        self.sup_label_file = read_text_file(os.path.join(self.root_dir , sup_label_file))\n",
    "        self.qry_file = read_text_file(os.path.join(self.root_dir , qry_file))\n",
    "        self.qry_label_file = read_text_file(os.path.join(self.root_dir , qry_label_file))\n",
    "        self.same_depth = 30\n",
    "        self.adaptive_size = (30,64,64)\n",
    "        # self.adaptive_size = (15,32,32)\n",
    "        assert len(self.sup_file) == len(self.sup_label_file), \"lengths of image files and fixation files do not match!\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sup_file)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        sup_img = self.compose_action(self.qry_file[idx])\n",
    "        sup_label_fg = self.compose_action(self.qry_label_file[idx])\n",
    "        sup_label_bg = torch.subtract(torch.ones_like(sup_label_fg), sup_label_fg)\n",
    "\n",
    "        \n",
    "        #qry_img = self.compose_transformation(self.qry_file[idx])\n",
    "        #qry_label_fg = self.compose_transformation(self.qry_label_file[idx])\n",
    "        \n",
    "    \n",
    "        qry_img = self.compose_transformation(self.qry_file[idx])\n",
    "        qry_label_fg = self.compose_transformation(self.qry_label_file[idx])\n",
    "        qry_label_bg = torch.subtract(torch.ones_like(qry_label_fg),  qry_label_fg)\n",
    "\n",
    "        sample = {\"sup_img\":sup_img, \"sup_fg_label\":sup_label_fg, \"qry_img\":qry_img, \"qry_label_fg\":qry_label_fg,\n",
    "         \"sup_bg_label\":sup_label_bg, \"qry_label_bg\":qry_label_bg}\n",
    "\n",
    "        return sample\n",
    "    \n",
    "   \n",
    "\n",
    "    def compose_action(self, file_name):\n",
    "        # read data as numpy array 3d\n",
    "        data = self.nii_read_and_cut(file_name)\n",
    "        \n",
    "\n",
    "        # Add another dummpy dimention for channel as 1\n",
    "        data = data[None,:]\n",
    "        # [1,same_depth, 256,256]\n",
    "\n",
    "        # To tensor\n",
    "        data = torch.as_tensor(data,dtype=torch.double)\n",
    "\n",
    "        # Avgpool\n",
    "        # ap = nn.AvgPool3d((2, 2, 1), stride=(2, 2, 2))\n",
    "        ap = nn.AdaptiveAvgPool3d(self.adaptive_size)\n",
    "        # ap = nn.AdaptiveAvgPool3d((None,64,64))\n",
    "        data = ap(data)\n",
    "        # [1, same_depteh, 128, 128]\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "    def compose_transformation(self, file_name):\n",
    "\n",
    "        data = sitk.ReadImage(file_name)\n",
    "\n",
    "        elastic_tr = tio.RandomElasticDeformation(num_control_points=7,locked_borders=2)\n",
    "        affine_tr = tio.transforms.RandomAffine(scales=(0.5, 1.5),degrees=(10,10,10))\n",
    "        gamma_tr = tio.RandomGamma(log_gamma=(-0.3,0.3))\n",
    "\n",
    "        ts = tio.Compose([gamma_tr,affine_tr,elastic_tr])\n",
    "\n",
    "        transformed = ts(data)\n",
    "        array = sitk.GetArrayFromImage(transformed)\n",
    "        # sitk.WriteImage(transformed,\"transformed_data.nii.gz\")\n",
    "# To tensor\n",
    "        array = array[None,:]\n",
    "        data = torch.as_tensor(array,dtype=torch.double)        \n",
    "\n",
    "\n",
    "        # Avgpool\n",
    "        # ap = nn.AvgPool3d((2, 2, 1), stride=(2, 2, 2))\n",
    "        ap = nn.AdaptiveAvgPool3d(self.adaptive_size)\n",
    "        # ap = nn.AdaptiveAvgPool3d((None,64,64))\n",
    "        data = ap(data)\n",
    "        # [1, same_depteh, 128, 128]\n",
    "\n",
    "        return data\n",
    "        \n",
    "    \n",
    "    def nii_read_and_cut(self, file_name):\n",
    "\n",
    "        # numpy.array 3D\n",
    "        data = nii_read(filename=file_name)\n",
    "        # cut depth the same as same_depth\n",
    "        data = data[:self.same_depth,:,:]\n",
    "\n",
    "        return data\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import pytorch3dunet.unet3d.model as model3dUnet\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "\n",
    "class SSL3DUNet(pl.LightningModule):\n",
    "    def __init__(self,batch_size = 1, lr=1e-3):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = lr\n",
    "        # self.criterion = nn.CrossEntropyLoss()\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "        self.avgPool = nn.AdaptiveAvgPool3d((None,8,8))\n",
    "        self.thresh = .95\n",
    "        unet3d = model3dUnet.UNet3D(1,1)\n",
    "        self.unet3d = unet3d.double()\n",
    "        self.params = list(unet3d.parameters())\n",
    "        self.automatic_optimization = False # use own optimizer\n",
    "        self.save_hyperparameters() # for comet.ML logger\n",
    "        print(\"Finish init SSL3DUNet Model\")\n",
    "    # def forward(batch, batch_idx):\n",
    "    #     return batch \n",
    "\n",
    "    def loss(self, batch, predictions):\n",
    "\n",
    "        sup_fg_label = batch[\"sup_fg_label\"] \n",
    "        sup_bg_label = batch[\"sup_bg_label\"] \n",
    "        qry_label_fg = batch[\"qry_label_fg\"]\n",
    "        qry_label_bg = batch[\"qry_label_bg\"]\n",
    "        sup_fts = predictions[\"sup_fts\"]\n",
    "        qry_fts = predictions[\"qry_fts\"]\n",
    "\n",
    "        qry_pred, sup_pred = self._pass_compose(sup_fts, qry_fts, sup_fg_label, sup_bg_label, qry_label_fg, qry_label_bg)\n",
    "        sig = nn.Sigmoid() \n",
    "        query_loss = self.criterion(sig(qry_pred),sig(qry_label_fg))\n",
    "        experiment.log_metric(\"query_loss\", query_loss)\n",
    "        sup_loss = self.criterion(sig(sup_pred),sig(sup_fg_label))\n",
    "        experiment.log_metric(\"sup_loss\", sup_loss)\n",
    "\n",
    "        loss = torch.add(query_loss , sup_loss )\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def training_step(self,batch, batch_idx):\n",
    "        opt = self.optimizers()\n",
    "        # batch: {\"sup_img\":sup_img, \"sup_label\":sup_label, \"qry_img\":qry_img, \"qry_label\":qry_label}\n",
    "        \n",
    "        sup_img = batch[\"sup_img\"] \n",
    "        qry_img = batch[\"qry_img\"] \n",
    "        \n",
    "    #   as -> [batch, channel, 30, 128 , 128] \n",
    "    #    -> [batch, 1, 30, 128 , 128] \n",
    "\n",
    "        sup_fts = self.unet3d(sup_img) \n",
    "        qry_fts = self.unet3d(qry_img) \n",
    "        predictions = {\"sup_fts\":sup_fts, \"qry_fts\":qry_fts} \n",
    "        opt.zero_grad()\n",
    "        loss = self.loss(batch,predictions)\n",
    "        self.manual_backward(loss)\n",
    "        opt.step()\n",
    "        experiment.log_metric(\"training loss\", loss)\n",
    "        return {\"loss\":loss} \n",
    "\n",
    "    def validation_step(self,batch, batch_idx):\n",
    "        # batch: {\"sup_img\":sup_img, \"sup_label\":sup_label, \"qry_img\":qry_img, \"qry_label\":qry_label}\n",
    "        sup_img = batch[\"sup_img\"] \n",
    "        qry_img = batch[\"qry_img\"] \n",
    "    #   as -> [batch, channel, 30, 128 , 128] \n",
    "    #    -> [batch, 1, 30, 128 , 128] \n",
    "        sup_fts = self.unet3d(sup_img) \n",
    "        qry_fts = self.unet3d(qry_img) \n",
    "\n",
    "        predictions = {\"sup_fts\":sup_fts, \"qry_fts\":qry_fts} \n",
    "        loss = self.loss(batch,predictions)\n",
    "        experiment.log_metric(\"validation loss\", loss)\n",
    "        return {\"x\":loss} \n",
    "        \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.params, lr=self.learning_rate)\n",
    "        # lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=0.1)\n",
    "        return [optimizer]\n",
    "    \n",
    "    def _pass_compose(self,sup_fts, qry_fts, sup_fg_label, sup_bg_label, qry_label_fg, qry_label_bg):\n",
    "        \n",
    "        raw_score_bg = self._alp_module(qry_fts,sup_fts,sup_bg_label,mode='local',thresh=self.thresh)\n",
    "        NO_OVER_THRES =  torch.all(torch.flatten(sup_fg_label < self.thresh))\n",
    "        raw_score_fg = self._alp_module(qry_fts,sup_fts,sup_fg_label,mode='global' if not NO_OVER_THRES else 'mask',thresh=self.thresh)\n",
    "        qry_pred = torch.div(torch.add(raw_score_bg, raw_score_fg),2)\n",
    "\n",
    "        re_raw_score_bg = self._alp_module(sup_fts,qry_fts,qry_label_bg,mode='local',thresh=self.thresh)\n",
    "        RES_NO_OVER_THRES =  torch.all(torch.flatten(qry_label_fg < self.thresh))\n",
    "        re_raw_score_fg = self._alp_module(sup_fts,qry_fts,qry_label_fg,mode='global' if not RES_NO_OVER_THRES else 'mask',thresh=self.thresh)\n",
    "        sup_pred = torch.div(torch.add(re_raw_score_bg, re_raw_score_fg),2)\n",
    "\n",
    "        return qry_pred, sup_pred\n",
    "\n",
    "    def _alp_module(self, qry_fts, sup_fts, sup_label, mode='global', thresh=.95):\n",
    "    \n",
    "        # [1, same_depteh, 16, 16]\n",
    "        if mode == 'local':\n",
    "            \n",
    "            ch = qry_fts.shape[1] # temp: 64\n",
    "\n",
    "            n_sup_x = self.avgPool(sup_fts)\n",
    "            sup_nshot = sup_fts.shape[0] # 1\n",
    "\n",
    "            n_sup_x = n_sup_x.view(sup_nshot,ch,-1).permute(0,2,1).unsqueeze(0)\n",
    "            n_sup_x = n_sup_x.reshape(1,-1,ch).unsqueeze(0)\n",
    "\n",
    "            sup_y = self.avgPool(sup_label) \n",
    "            sup_y = sup_y.view(sup_nshot,1,-1)\n",
    "            sup_y = sup_y.permute(1,0,2).view(1,-1).unsqueeze(0)\n",
    "\n",
    "            pro_n = n_sup_x[sup_y > thresh,:]\n",
    "\n",
    "            qry_n = self._safe_norm(qry_fts) \n",
    "\n",
    "            dists = F.conv3d(qry_n,pro_n[...,None,None,None]) * 20\n",
    "            pred_grid =  torch.sum(F.softmax(dists,dim=1)*dists, dim=1,keepdim=True)\n",
    "            return pred_grid\n",
    "            \n",
    "        elif mode == 'global':\n",
    "            \n",
    "            ch = qry_fts.shape[1] # temp: 64\n",
    "\n",
    "            n_sup_x = self.avgPool(sup_fts)\n",
    "            sup_nshot = sup_fts.shape[0] # 1\n",
    "\n",
    "            n_sup_x = n_sup_x.view(sup_nshot,ch,-1).permute(0,2,1).unsqueeze(0)\n",
    "            n_sup_x = n_sup_x.reshape(1,-1,ch).unsqueeze(0)\n",
    "\n",
    "            sup_y = self.avgPool(sup_label) \n",
    "            sup_y = sup_y.view(sup_nshot,1,-1)\n",
    "            sup_y = sup_y.permute(1,0,2).view(1,-1).unsqueeze(0)\n",
    "\n",
    "            pro_n = n_sup_x[sup_y > thresh,:]\n",
    "\n",
    "            ##################\n",
    "            # global\n",
    "            glb_proto = torch.sum(sup_fts * sup_label, dim=(-1,-2,-3)) / (sup_label.sum(dim=(-1,-2,-3)) + 1e-5)\n",
    "            pro_n = self._safe_norm(torch.cat([pro_n, glb_proto], dim=0))\n",
    "            qry_n = self._safe_norm(qry_fts) \n",
    "            ##############\n",
    "\n",
    "            dists = F.conv3d(qry_n,pro_n[...,None,None,None]) * 20\n",
    "            pred_grid =  torch.sum(F.softmax(dists,dim=1)*dists, dim=1,keepdim=True)\n",
    "            \n",
    "            return pred_grid\n",
    "            \n",
    "        elif mode == 'mask':\n",
    "            proto = torch.sum(sup_fts * sup_label, dim=(-1,-2,-3)) / (sup_label.sum(dim=(-1,-2,-3)) + 1e-5)\n",
    "            proto = proto.mean(dim=0, keepdim=True)\n",
    "            pred_mask = F.cosine_similarity(qry_fts, proto[..., None,None], dim=1, eps=1e-4) * 20\n",
    "\n",
    "            return pred_mask.unsqueeze(1)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    def _safe_norm(self, input, p=2, dim = 1, eps = 1e-4):\n",
    "        x_norm = torch.norm(input,p=p,dim=dim)\n",
    "        x_norm = torch.max(x_norm,torch.ones_like(x_norm,requires_grad=False)*eps )\n",
    "        output = input.div(x_norm.unsqueeze(1).expand_as(input))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CometLogger will be initialized in online mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish init SSL3DUNet Model\n"
     ]
    },
    {
     "ename": "MisconfigurationException",
     "evalue": "`Trainer(strategy='ddp_spawn')` or `Trainer(accelerator='ddp_spawn')` is not compatible with an interactive environment. Run your code as a script, or choose one of the compatible strategies: Trainer(strategy=None|dp|tpu_spawn). In case you are spawning processes yourself, make sure to include the Trainer creation inside the worker function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[1;32m/homeL/1sliu/code/SSL_UNet3D/ssl_my.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2274616d7347505534227d/homeL/1sliu/code/SSL_UNet3D/ssl_my.ipynb#ch0000003vscode-remote?line=8'>9</a>\u001b[0m comet_logger \u001b[39m=\u001b[39m CometLogger(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2274616d7347505534227d/homeL/1sliu/code/SSL_UNet3D/ssl_my.ipynb#ch0000003vscode-remote?line=9'>10</a>\u001b[0m     api_key\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m4e45dKB4oaj3YgKFrQ0MhPld1\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2274616d7347505534227d/homeL/1sliu/code/SSL_UNet3D/ssl_my.ipynb#ch0000003vscode-remote?line=10'>11</a>\u001b[0m     rest_api_key\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m4e45dKB4oaj3YgKFrQ0MhPld1\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2274616d7347505534227d/homeL/1sliu/code/SSL_UNet3D/ssl_my.ipynb#ch0000003vscode-remote?line=11'>12</a>\u001b[0m     optimizer_data\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mparameters(),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2274616d7347505534227d/homeL/1sliu/code/SSL_UNet3D/ssl_my.ipynb#ch0000003vscode-remote?line=12'>13</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2274616d7347505534227d/homeL/1sliu/code/SSL_UNet3D/ssl_my.ipynb#ch0000003vscode-remote?line=15'>16</a>\u001b[0m \u001b[39m# trainer = pl.Trainer(fast_dev_run=False, accelerator='gpu',devices=[1],log_every_n_steps=10, max_epochs=10, max_steps=10,logger=[comet_logger])\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2274616d7347505534227d/homeL/1sliu/code/SSL_UNet3D/ssl_my.ipynb#ch0000003vscode-remote?line=16'>17</a>\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39;49mTrainer(fast_dev_run\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, accelerator\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mgpu\u001b[39;49m\u001b[39m'\u001b[39;49m,devices\u001b[39m=\u001b[39;49m[\u001b[39m0\u001b[39;49m,\u001b[39m1\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2274616d7347505534227d/homeL/1sliu/code/SSL_UNet3D/ssl_my.ipynb#ch0000003vscode-remote?line=17'>18</a>\u001b[0m train_loader \u001b[39m=\u001b[39m DataLoader(train,batch_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,num_workers\u001b[39m=\u001b[39m\u001b[39m24\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2274616d7347505534227d/homeL/1sliu/code/SSL_UNet3D/ssl_my.ipynb#ch0000003vscode-remote?line=18'>19</a>\u001b[0m val_loader \u001b[39m=\u001b[39m DataLoader(val,batch_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,num_workers\u001b[39m=\u001b[39m\u001b[39m24\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/unet3d/lib/python3.8/site-packages/pytorch_lightning/utilities/argparse.py:339\u001b[0m, in \u001b[0;36m_defaults_from_env_vars.<locals>.insert_env_defaults\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mlist\u001b[39m(env_variables\u001b[39m.\u001b[39mitems()) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(kwargs\u001b[39m.\u001b[39mitems()))\n\u001b[1;32m    338\u001b[0m \u001b[39m# all args were already moved to kwargs\u001b[39;00m\n\u001b[0;32m--> 339\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/unet3d/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:485\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, logger, checkpoint_callback, enable_checkpointing, callbacks, default_root_dir, gradient_clip_val, gradient_clip_algorithm, process_position, num_nodes, num_processes, devices, gpus, auto_select_gpus, tpu_cores, ipus, log_gpu_memory, progress_bar_refresh_rate, enable_progress_bar, overfit_batches, track_grad_norm, check_val_every_n_epoch, fast_dev_run, accumulate_grad_batches, max_epochs, min_epochs, max_steps, min_steps, max_time, limit_train_batches, limit_val_batches, limit_test_batches, limit_predict_batches, val_check_interval, flush_logs_every_n_steps, log_every_n_steps, accelerator, strategy, sync_batchnorm, precision, enable_model_summary, weights_summary, weights_save_path, num_sanity_val_steps, resume_from_checkpoint, profiler, benchmark, deterministic, reload_dataloaders_every_n_epochs, auto_lr_find, replace_sampler_ddp, detect_anomaly, auto_scale_batch_size, prepare_data_per_node, plugins, amp_backend, amp_level, move_metrics_to_cpu, multiple_trainloader_mode, stochastic_weight_avg, terminate_on_nan)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39m# init connectors\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector \u001b[39m=\u001b[39m DataConnector(\u001b[39mself\u001b[39m, multiple_trainloader_mode)\n\u001b[0;32m--> 485\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accelerator_connector \u001b[39m=\u001b[39m AcceleratorConnector(\n\u001b[1;32m    486\u001b[0m     num_processes\u001b[39m=\u001b[39;49mnum_processes,\n\u001b[1;32m    487\u001b[0m     devices\u001b[39m=\u001b[39;49mdevices,\n\u001b[1;32m    488\u001b[0m     tpu_cores\u001b[39m=\u001b[39;49mtpu_cores,\n\u001b[1;32m    489\u001b[0m     ipus\u001b[39m=\u001b[39;49mipus,\n\u001b[1;32m    490\u001b[0m     accelerator\u001b[39m=\u001b[39;49maccelerator,\n\u001b[1;32m    491\u001b[0m     strategy\u001b[39m=\u001b[39;49mstrategy,\n\u001b[1;32m    492\u001b[0m     gpus\u001b[39m=\u001b[39;49mgpus,\n\u001b[1;32m    493\u001b[0m     num_nodes\u001b[39m=\u001b[39;49mnum_nodes,\n\u001b[1;32m    494\u001b[0m     sync_batchnorm\u001b[39m=\u001b[39;49msync_batchnorm,\n\u001b[1;32m    495\u001b[0m     benchmark\u001b[39m=\u001b[39;49mbenchmark,\n\u001b[1;32m    496\u001b[0m     replace_sampler_ddp\u001b[39m=\u001b[39;49mreplace_sampler_ddp,\n\u001b[1;32m    497\u001b[0m     deterministic\u001b[39m=\u001b[39;49mdeterministic,\n\u001b[1;32m    498\u001b[0m     auto_select_gpus\u001b[39m=\u001b[39;49mauto_select_gpus,\n\u001b[1;32m    499\u001b[0m     precision\u001b[39m=\u001b[39;49mprecision,\n\u001b[1;32m    500\u001b[0m     amp_type\u001b[39m=\u001b[39;49mamp_backend,\n\u001b[1;32m    501\u001b[0m     amp_level\u001b[39m=\u001b[39;49mamp_level,\n\u001b[1;32m    502\u001b[0m     plugins\u001b[39m=\u001b[39;49mplugins,\n\u001b[1;32m    503\u001b[0m )\n\u001b[1;32m    504\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_logger_connector \u001b[39m=\u001b[39m LoggerConnector(\u001b[39mself\u001b[39m, log_gpu_memory)\n\u001b[1;32m    505\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callback_connector \u001b[39m=\u001b[39m CallbackConnector(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/unet3d/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:217\u001b[0m, in \u001b[0;36mAcceleratorConnector.__init__\u001b[0;34m(self, devices, num_nodes, accelerator, strategy, plugins, precision, amp_type, amp_level, sync_batchnorm, benchmark, replace_sampler_ddp, deterministic, auto_select_gpus, num_processes, tpu_cores, ipus, gpus)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_and_init_precision()\n\u001b[1;32m    216\u001b[0m \u001b[39m# 6. Instantiate Strategy - Part 2\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lazy_init_strategy()\n",
      "File \u001b[0;32m~/anaconda3/envs/unet3d/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:788\u001b[0m, in \u001b[0;36mAcceleratorConnector._lazy_init_strategy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutilities\u001b[39;00m \u001b[39mimport\u001b[39;00m _IS_INTERACTIVE\n\u001b[1;32m    787\u001b[0m \u001b[39mif\u001b[39;00m _IS_INTERACTIVE \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mis_interactive_compatible:\n\u001b[0;32m--> 788\u001b[0m     \u001b[39mraise\u001b[39;00m MisconfigurationException(\n\u001b[1;32m    789\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`Trainer(strategy=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mstrategy_name\u001b[39m!r}\u001b[39;00m\u001b[39m)` or\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    790\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m `Trainer(accelerator=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mstrategy_name\u001b[39m!r}\u001b[39;00m\u001b[39m)` is not compatible with an interactive\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    791\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m environment. Run your code as a script, or choose one of the compatible strategies:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    792\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m Trainer(strategy=None|\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m|\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(_StrategyType\u001b[39m.\u001b[39minteractive_compatible_types())\u001b[39m}\u001b[39;00m\u001b[39m).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    793\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m In case you are spawning processes yourself, make sure to include the Trainer\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    794\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m creation inside the worker function.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    795\u001b[0m     )\n\u001b[1;32m    797\u001b[0m \u001b[39m# TODO: should be moved to _check_strategy_and_fallback().\u001b[39;00m\n\u001b[1;32m    798\u001b[0m \u001b[39m# Current test check precision first, so keep this check here to meet error order\u001b[39;00m\n\u001b[1;32m    799\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator, TPUAccelerator) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[1;32m    800\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy, (SingleTPUStrategy, TPUSpawnStrategy)\n\u001b[1;32m    801\u001b[0m ):\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: `Trainer(strategy='ddp_spawn')` or `Trainer(accelerator='ddp_spawn')` is not compatible with an interactive environment. Run your code as a script, or choose one of the compatible strategies: Trainer(strategy=None|dp|tpu_spawn). In case you are spawning processes yourself, make sure to include the Trainer creation inside the worker function."
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.utils.data import random_split,DataLoader \n",
    "import torchio.transforms as transforms \n",
    "from pytorch_lightning.loggers import CometLogger\n",
    "\n",
    "torch.manual_seed(0) # set default seed for torch operation\n",
    "dataset = SSLDataset(base_dir,sup_img_file,sup_label_file,qry_img_file,qry_label_file)\n",
    "train, val = random_split(dataset,[16,4])\n",
    "model = SSL3DUNet()\n",
    "comet_logger = CometLogger(\n",
    "    api_key=\"4e45dKB4oaj3YgKFrQ0MhPld1\",\n",
    "    rest_api_key=\"4e45dKB4oaj3YgKFrQ0MhPld1\",\n",
    "    optimizer_data=model.parameters(),\n",
    ")\n",
    "\n",
    "\n",
    "# trainer = pl.Trainer(fast_dev_run=False, accelerator='gpu',devices=[1],log_every_n_steps=10, max_epochs=10, max_steps=10,logger=[comet_logger])\n",
    "trainer = pl.Trainer(fast_dev_run=False, accelerator='gpu',devices=[0,1])\n",
    "train_loader = DataLoader(train,batch_size=1,num_workers=24)\n",
    "val_loader = DataLoader(val,batch_size=1,num_workers=24)\n",
    "\n",
    "print(\"strat trainning\")\n",
    "trainer.fit(model, train_loader, val_loader )\n",
    "print(\"end trainning\")\n",
    "\n",
    "experiment.end()\n",
    "######################################################################################################## STOP HERE ########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish init SSL3DUNet Model\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "# avgPool = nn.AdaptiveAvgPool3d((None,8,8))\n",
    "# thresh = .95\n",
    "# unet3d = model3dUnet.UNet3D(1,1)\n",
    "# unet3d_d = unet3d.double()\n",
    "# params = unet3d.parameters()\n",
    "model = SSL3DUNet()\n",
    "# unet3d = model3dUnet.UNet3D(1,1)\n",
    "import pickle\n",
    "with open('test.pickle', 'wb') as handle:\n",
    "    pickle.dump(model,handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "AttributeError: partially initialized module 'ssl' has no attribute 'PROTOCOL_TLSv1' (most likely due to a circular import). \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# import torch.nn as nn\n",
    "# import torch\n",
    "# from torch.nn import functional as F\n",
    "# # pool of square window of size=3, stride=2\n",
    "# m = nn.AvgPool3d(3, stride=2)\n",
    "# # pool of non-square window\n",
    "# # m = nn.AvgPool3d((2, 2, 1), stride=(2, 2, 2))\n",
    "\n",
    "# # m = nn.AvgPool3d((4, 4, 1), stride=(1, 4, 4))\n",
    "# m = nn.AdaptiveAvgPool3d((None,128,128))\n",
    "# input = torch.randn(1, 32, 32, 32)\n",
    "# t = torch.randn( 16, 32)\n",
    "# output = F.conv2d(input, t[...,None,None])*20\n",
    "\n",
    "# # x_norm = torch.norm(input,p=2,dim=1)\n",
    "# # x_norm = torch.max(x_norm,torch.ones_like(x_norm)*1e-4 )\n",
    "# # output = input.div(x_norm.unsqueeze(1).expand_as(input))\n",
    "# # input = torch.randn(1, 1, 31,256, 256)\n",
    "# # input = torch.randn(1, 1, 15,128, 128)\n",
    "# # output = m(input)\n",
    "# #output = input.squeeze(0)\n",
    "# print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "t1.shape:torch.Size([1, 1, 256, 256])\n",
      "t2.shape:torch.Size([1, 1, 256, 256])\n",
      "input shape:torch.Size([1, 256, 16, 16])\n",
      "y1 shape:torch.Size([1, 1, 256])\n",
      "y2 shape:torch.Size([1, 1, 256])\n",
      "y3 shpae:torch.Size([1, 256])\n",
      "y4 shape:torch.Size([1, 1, 256])\n",
      "pro_n.shape:torch.Size([52, 256])\n",
      "pro_n global shape:torch.Size([53, 256])\n",
      "qry_n global shape:torch.Size([1, 256, 32, 32])\n",
      "dists sahpe:torch.Size([1, 53, 32, 32])\n",
      "pred_grid.shape:torch.Size([1, 1, 32, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homeL/1sliu/anaconda3/envs/unet3d/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# 2D testing\n",
    "# 64,15,128,128\n",
    "# 64, 1, 1, 1 as prototype\n",
    "#\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "def safe_norm( input, p=2, dim = 1, eps = 1e-4):\n",
    "    x_norm = torch.norm(input,p=p,dim=dim)\n",
    "    x_norm = torch.max(x_norm,torch.ones_like(x_norm)*eps )\n",
    "    output = input.div(x_norm.unsqueeze(1).expand_as(input))\n",
    "    return output\n",
    "\n",
    "\n",
    "sup_x = torch.randn( 1,256, 32, 32)\n",
    "sup_y = torch.randn( 1,256, 32, 32)\n",
    "glb_proto = torch.sum(sup_x * sup_y, dim=(-1,-2)) / (sup_y.sum(dim=(-1,-2)) + 1e-5)\n",
    "print(glb_proto.shape)\n",
    "\n",
    "\n",
    "input = torch.randn( 1,256, 16, 16)\n",
    "qry_n = torch.randn( 1,256, 32, 32)\n",
    "\n",
    "\n",
    "t1 = input.view(1,256,-1).permute(0,2,1).unsqueeze(0)\n",
    "print(input.view(1,256,-1).shape)\n",
    "print(f\"t1.shape:{t1.shape}\")\n",
    "t2 = t1.reshape(1,-1,256).unsqueeze(0)\n",
    "print(f\"t2.shape:{t2.shape}\")\n",
    "\n",
    "sup_y = torch.randn( 1,1, 16, 16)\n",
    "print(f\"input shape:{input.shape}\")\n",
    "y1 = sup_y.view(1,1,-1)\n",
    "print(f\"y1 shape:{y1.shape}\")\n",
    "y2 = y1.permute(1,0,2)\n",
    "print(f\"y2 shape:{y2.shape}\")\n",
    "y3 = y2.view(1,-1)\n",
    "print(f\"y3 shpae:{y3.shape}\")\n",
    "y4 = y3.unsqueeze(0)\n",
    "print(f\"y4 shape:{y4.shape}\")\n",
    "\n",
    "pro_n = t2[y4 > 0.95,:]\n",
    "print(f\"pro_n.shape:{pro_n.shape}\")\n",
    "\n",
    "# for global\n",
    "pro_n = safe_norm(torch.cat([pro_n, glb_proto], dim=0))\n",
    "print(f\"pro_n global shape:{pro_n.shape}\")\n",
    "qry_n = safe_norm(qry_n)\n",
    "print(f\"qry_n global shape:{qry_n.shape}\")\n",
    "\n",
    "dists = F.conv2d(qry_n,pro_n[...,None,None]) * 20\n",
    "print(f\"dists sahpe:{dists.shape}\")\n",
    "pred_grid =  torch.sum(F.softmax(dists,dim=1)*dists, dim=1,keepdim=True)\n",
    "print(f\"pred_grid.shape:{pred_grid.shape}\")\n",
    "\n",
    "sup_pred = torch.cat([pred_grid,], dim=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "8\n",
      "[0, 1, 2, 3, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19] [4, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "k_fold = 5\n",
    "seg = 1\n",
    "total_data_size = 20\n",
    "indices = list(range(total_data_size))\n",
    "base = int(numpy.floor(1/k_fold * total_data_size))\n",
    "split_start = base * seg \n",
    "split_end = base* (seg+1) \n",
    "print(base)\n",
    "print(split_start)\n",
    "print(split_end)\n",
    "print(indices[:split_start]+indices[split_end:],indices[split_start:split_end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "AttributeError: partially initialized module 'ssl' has no attribute 'PROTOCOL_TLSv1' (most likely due to a circular import). \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "# ch = 64\n",
    "\n",
    "# sup_x = torch.randn( 1,ch, 30, 256, 256)\n",
    "# sup_y = torch.randn( 1,ch, 30, 256, 256)\n",
    "# glb_proto = torch.sum(sup_x * sup_y, dim=(-1,-2,-3)) / (sup_y.sum(dim=(-1,-2,-3)) + 1e-5)\n",
    "# print(glb_proto.shape)\n",
    "\n",
    "# input = torch.randn( 1, ch,30, 16, 16)\n",
    "# qry_n = torch.randn( 1,ch, 30, 256, 256)\n",
    "\n",
    "\n",
    "# t1 = input.view(1,ch,-1).permute(0,2,1).unsqueeze(0)\n",
    "# print(f\"t1.shape:{t1.shape}\")\n",
    "# t2 = t1.reshape(1,-1,ch).unsqueeze(0)\n",
    "# print(f\"t2.shape:{t2.shape}\")\n",
    "\n",
    "# nb = 1\n",
    "# nshot = 1\n",
    "# sup_y = torch.randn( nshot,nb, 30, 16, 16)\n",
    "# y1 = sup_y.view(1,1,-1)\n",
    "# print(f\"y1 shape:{y1.shape}\")\n",
    "# y2 = y1.permute(1,0,2)\n",
    "# print(f\"y2 shape:{y2.shape}\")\n",
    "# y3 = y2.view(1,-1)\n",
    "# print(f\"y3 shpae:{y3.shape}\")\n",
    "# y4 = y3.unsqueeze(0)\n",
    "# print(f\"y4 shape:{y4.shape}\")\n",
    "\n",
    "# pro_n = t2[y4 > 0.95,:]\n",
    "# print(f\"pro_n.shape:{pro_n.shape}\")\n",
    "\n",
    "\n",
    "# # for global\n",
    "# pro_n = safe_norm(torch.cat([pro_n, glb_proto], dim=0))\n",
    "# print(f\"pro_n global shape:{pro_n.shape}\")\n",
    "# qry_n = safe_norm(qry_n)\n",
    "# print(f\"qry_n global shape:{qry_n.shape}\")\n",
    "\n",
    "# dists = F.conv3d(qry_n,pro_n[...,None,None,None]) * 20\n",
    "# print(f\"dists sahpe:{dists.shape}\")\n",
    "# pred_grid =  torch.sum(F.softmax(dists,dim=1)*dists, dim=1,keepdim=True)\n",
    "# print(f\"pred_grid.shape:{pred_grid.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "AttributeError: partially initialized module 'ssl' has no attribute 'PROTOCOL_TLSv1' (most likely due to a circular import). \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import torch\n",
    "# a = torch.rand(1,3,2,1)\n",
    "# print(a)\n",
    "# print(a.shape)\n",
    "# b = a.argmax(dim=1).unsqueeze(0)\n",
    "# c = [b==i for i in range(2)]\n",
    "# c[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "AttributeError: partially initialized module 'ssl' has no attribute 'PROTOCOL_TLSv1' (most likely due to a circular import). \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# # sup_x = 16*16*256\n",
    "# # BG_mask = 16*16\n",
    "# # \n",
    "# a = torch.rand(1,1,2,15,32,32)\n",
    "# a.view(-1,*a[:-4]).shape\n",
    "# a.view((1,1,1,30,32,32)).shape\n",
    "# #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "AttributeError: partially initialized module 'ssl' has no attribute 'PROTOCOL_TLSv1' (most likely due to a circular import). \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# # Declarations (dummy tensors)\n",
    "# rgb_im = torch.randint(0, 255, [1, 3, 256, 256])\n",
    "# depth = torch.randint(0, 400, [1, 1, 256, 256])\n",
    "\n",
    "# # Calculations\n",
    "# depth_ohe = F.one_hot(depth, num_classes=400)       # of shape (batch, channel, height, width, binary)\n",
    "# print(depth_ohe.shape)\n",
    "# bchwd_tensor = rgb_im.unsqueeze(-1)*depth_ohe       # of shape (batch, channel, height, width, depth)\n",
    "# print(bchwd_tensor.shape)\n",
    "# bcdhw_tensor = bchwd_tensor.permute(0, 1, 4, 2, 3)  # of shape (batch, channel, depth, height, width)\n",
    "# print(bcdhw_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "AttributeError: partially initialized module 'ssl' has no attribute 'PROTOCOL_TLSv1' (most likely due to a circular import). \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "AttributeError: partially initialized module 'ssl' has no attribute 'PROTOCOL_TLSv1' (most likely due to a circular import). \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from medpy.io import load\n",
    "import numpy\n",
    "\n",
    "# copy spacing and orientation info between sitk objects\n",
    "def copy_info(src, dst):\n",
    "    dst.SetSpacing(src.GetSpacing())\n",
    "    dst.SetOrigin(src.GetOrigin())\n",
    "    dst.SetDirection(src.GetDirection())\n",
    "    #dst.CopyInfomation(src)\n",
    "    return dst\n",
    "\n",
    "def nii_read(filename):\n",
    "    # print(f\"nii_resad:{filename}\")\n",
    "    # voxel_obj =  sitk.ReadImage(filename)\n",
    "    # print(voxel_obj)\n",
    "    # voxel_arr = sitk.GetArrayFromImage(voxel_obj) \n",
    "    # print(voxel_arr.shape)\n",
    "    voxel_arr,voxel_header = load(filename)\n",
    "    voxel_arr = numpy.swapaxes(voxel_arr,0,2)\n",
    "    return voxel_arr\n",
    "    \n",
    "def nii_read_and_cut(file_name):\n",
    "\n",
    "# numpy.array 3D\n",
    "    data = nii_read(filename=file_name)\n",
    "# cut depth the same as same_depth\n",
    "    data = data[:30,:,:]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "AttributeError: partially initialized module 'ssl' has no attribute 'PROTOCOL_TLSv1' (most likely due to a circular import). \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torchio as tio\n",
    "import os\n",
    "import SimpleITK as sitk\n",
    "import nibabel as nib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "elastic_tr = tio.RandomElasticDeformation(\n",
    "    num_control_points=7,\n",
    "    locked_borders=2,\n",
    ")\n",
    "affine_tr = tio.transforms.RandomAffine(\n",
    "    scales=(0.5, 1.5),\n",
    "    degrees=(10,10,10),\n",
    ")\n",
    "gamma_tr = tio.RandomGamma(\n",
    "    log_gamma=(-0.3,0.3)\n",
    ")\n",
    "\n",
    "ts = tio.Compose([\n",
    "    gamma_tr,\n",
    "    affine_tr,\n",
    "    elastic_tr,\n",
    "])\n",
    "\n",
    "img_path = './data/CHAOST2/chaos_MR_T2_normalized'\n",
    "img = 'image_1.nii.gz'\n",
    "file_name = os.path.join(img_path,img)\n",
    "print(file_name)\n",
    "# data = nii_read_and_cut(file_name)\n",
    "data = sitk.ReadImage(file_name)\n",
    "print(type(data))\n",
    "# print(data.shape)\n",
    "# data = data[None,:]\n",
    "transformed = ts(data)\n",
    "array = sitk.GetArrayFromImage(transformed)\n",
    "print(array.shape)\n",
    "print(type(array))\n",
    "# print(transformed.shape)\n",
    "# data = numpy.squeeze(data,axis=0)\n",
    "# data = numpy.swapaxes(data, 0,2)\n",
    "# data_img = nib.Nifti1Image(data,numpy.eye(4))\n",
    "# nib.save(data_img, \"transformed_data.nii.gz\")\n",
    "sitk.WriteImage(transformed,\"transformed_data.nii.gz\")\n",
    "# To tensor\n",
    "array = array[None,:]\n",
    "data = torch.as_tensor(array,dtype=torch.double)\n",
    "\n",
    "# Avgpool\n",
    "# ap = nn.AvgPool3d((2, 2, 1), stride=(2, 2, 2))\n",
    "ap = nn.AdaptiveAvgPool3d((30,32,32))\n",
    "# ap = nn.AdaptiveAvgPool3d((None,64,64))\n",
    "data = ap(data)\n",
    "data = data.detach().numpy()\n",
    "data = numpy.squeeze(data,axis=0)\n",
    "data_img = nib.Nifti1Image(data,numpy.eye(4))\n",
    "nib.save(data_img, \"transformed_data_Pool.nii.gz\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "AttributeError: partially initialized module 'ssl' has no attribute 'PROTOCOL_TLSv1' (most likely due to a circular import). \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "def compose_transformation(self, file_name):\n",
    "\n",
    "        #if label -> no gamma transform (does it even make a difference?)\n",
    "        # read data as numpy array 3d\n",
    "        data = self.nii_read_and_cut(file_name)\n",
    "        \n",
    "\n",
    "        # Add another dummpy dimention for channel as 1\n",
    "        data = data[None,:]\n",
    "        # [1,same_depth, 256,256]\n",
    "\n",
    "        # To tensor\n",
    "        #data = torch.as_tensor(data,dtype=torch.double)\n",
    "        #TO NII\n",
    "\n",
    "        elastic_tr = tio.RandomElasticDeformation(num_control_points=7,locked_borders=2)\n",
    "        affine_tr = tio.transforms.RandomAffine(scales=(0.5, 1.5),degrees=(10,10,10))\n",
    "        gamma_tr = tio.RandomGamma(log_gamma=(-0.3,0.3))\n",
    "\n",
    "        ts = tio.Compose([gamma_tr,affine_tr,elastic_tr])\n",
    "\n",
    "        transformed = ts(data)\n",
    "        array = sitk.GetArrayFromImage(transformed)\n",
    "        sitk.WriteImage(transformed,\"transformed_data.nii.gz\")\n",
    "# To tensor\n",
    "        array = array[None,:]\n",
    "        data = torch.as_tensor(array,dtype=torch.double)        \n",
    "\n",
    "\n",
    "        # Avgpool\n",
    "        # ap = nn.AvgPool3d((2, 2, 1), stride=(2, 2, 2))\n",
    "        ap = nn.AdaptiveAvgPool3d((15,32,32))\n",
    "        # ap = nn.AdaptiveAvgPool3d((None,64,64))\n",
    "        data = ap(data)\n",
    "        # [1, same_depteh, 128, 128]\n",
    "\n",
    "        return data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('unet3d')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05f2d1a0c395dbcbe4c9360e9d03ffb3e8b47f17932c57d7b4eaccbd70357b44"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
