{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate read order txt file\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "\n",
    "base_dir =\"/homeL/1sliu/code/SSL_UNet3D/data/CHAOST2/chaos_MR_T2_normalized\"\n",
    "sup_img_re = \"image*.nii.gz\" \n",
    "sup_label_re = \"superpix3d*.nii.gz\" \n",
    "qry_img_re = \"image*.nii.gz\" \n",
    "qry_label_re = \"label*.nii.gz\"\n",
    "\n",
    "sup_img_file = \"sup_img_file.txt\"\n",
    "sup_label_file = \"sup_label_file.txt\"\n",
    "qry_img_file = \"qry_img_file.txt\"\n",
    "qry_label_file = \"qry_label_file.txt\"\n",
    "\n",
    "\n",
    "def getNameList(base_dir,data_re):\n",
    "    data_file_names = []\n",
    "    for file_name in glob.glob(os.path.join(base_dir,data_re)):\n",
    "        data_file_names.append(file_name)\n",
    "    return data_file_names\n",
    "\n",
    "def writeNameFile(lines, base_dir, write_with_file_name=\"None.txt\"):\n",
    "    file_path = os.path.join(base_dir,write_with_file_name)\n",
    "    with open(file_path,'w') as f:\n",
    "        for line in lines:\n",
    "            f.write(line)\n",
    "            f.write('\\n')\n",
    "\n",
    "sup_img_names = getNameList(base_dir, sup_img_re)\n",
    "sup_label_names = getNameList(base_dir, sup_label_re)\n",
    "\n",
    "# shuffle order together\n",
    "c = list(zip(sup_img_names,sup_label_names))\n",
    "random.Random(4).shuffle(c)\n",
    "sup_img_names,sup_label_names = zip(*c) \n",
    "\n",
    "# with original order\n",
    "qry_img_names = getNameList(base_dir, qry_img_re)\n",
    "qry_label_names = getNameList(base_dir, qry_label_re)\n",
    "\n",
    "writeNameFile(sup_img_names,base_dir,write_with_file_name=sup_img_file)\n",
    "writeNameFile(sup_label_names,base_dir,write_with_file_name=sup_label_file)\n",
    "writeNameFile(qry_img_names,base_dir,write_with_file_name=qry_img_file)\n",
    "writeNameFile(qry_label_names,base_dir,write_with_file_name=qry_label_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/fabzhang/ssl/eb0f4197fda54c4ba68ce0d0680f69b4\n",
      "\n",
      "/homeL/1sliu/anaconda3/envs/unet3d/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Before everythings\n",
    "import comet_ml\n",
    "\n",
    "# Create an experiment with your api key\n",
    "experiment = comet_ml.Experiment(\n",
    "    api_key=\"4e45dKB4oaj3YgKFrQ0MhPld1\",\n",
    "    project_name=\"ssl\",\n",
    ")\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import SimpleITK as sitk\n",
    "import torch.nn as nn\n",
    "from medpy.io import load\n",
    "import torchio as tio\n",
    "import nibabel as nib\n",
    "import numpy\n",
    "from pytorch3dunet.datasets.utils import SliceBuilder \n",
    "\n",
    "\n",
    "\n",
    "def read_text_file(filename):\n",
    "    lines = []\n",
    "    # print(f\"start to read text file:{filename}\")\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file: \n",
    "            # print(f\"line:{line}\")\n",
    "            line = line.strip() #or some other preprocessing\n",
    "            lines.append(line)\n",
    "    # print(f\"length of text file:{len(lines)}\")\n",
    "    return lines\n",
    "\n",
    "def nii_read(filename):\n",
    "    # print(f\"nii_resad:{filename}\")\n",
    "    # voxel_obj =  sitk.ReadImage(filename)\n",
    "    # print(voxel_obj)\n",
    "    # voxel_arr = sitk.GetArrayFromImage(voxel_obj) \n",
    "    # print(voxel_arr.shape)\n",
    "    voxel_arr,voxel_header = load(filename)\n",
    "    voxel_arr = numpy.swapaxes(voxel_arr,0,2)\n",
    "    return voxel_arr\n",
    "########\n",
    "# # test nii_read code\n",
    "# import numpy\n",
    "# import torchio.transforms as transforms\n",
    "# test_data_file = \"./data/CHAOST2/chaos_MR_T2_normalized/image_1.nii.gz\"\n",
    "# vox_arr = nii_read(test_data_file)\n",
    "# print(vox_arr.shape)\n",
    "# swap_ax =numpy.swapaxes(vox_arr,0,2)\n",
    "# cut_depth = swap_ax[:31,:,:]\n",
    "# add_di = cut_depth[None,:]\n",
    "# print(add_di.shape)\n",
    "# result = torch.as_tensor(add_di)\n",
    "# print(result.shape)\n",
    "\n",
    "#########\n",
    "\n",
    "class SSLDataset(Dataset):\n",
    "    def __init__(self, root_dir, sup_file, sup_label_file, qry_file, qry_label_file):\n",
    "        self.root_dir = root_dir\n",
    "        self.sup_file = read_text_file(os.path.join(self.root_dir, sup_file))\n",
    "        self.sup_label_file = read_text_file(os.path.join(self.root_dir , sup_label_file))\n",
    "        self.qry_file = read_text_file(os.path.join(self.root_dir , qry_file))\n",
    "        self.qry_label_file = read_text_file(os.path.join(self.root_dir , qry_label_file))\n",
    "        self.same_depth = 30\n",
    "        #self.adaptive_size = (15,64,64)\n",
    "        self.adaptive_size = (15,32,32)\n",
    "        assert len(self.sup_file) == len(self.sup_label_file), \"lengths of image files and fixation files do not match!\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sup_file)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        sup_img = self.compose_action(self.qry_file[idx])\n",
    "        sup_label_fg = self.compose_action(self.qry_label_file[idx])\n",
    "        sup_label_bg = torch.subtract(torch.ones_like(sup_label_fg), sup_label_fg)\n",
    "\n",
    "        \n",
    "        #qry_img = self.compose_transformation(self.qry_file[idx])\n",
    "        #qry_label_fg = self.compose_transformation(self.qry_label_file[idx])\n",
    "        \n",
    "    \n",
    "        qry_img = self.compose_transformation(self.qry_file[idx])\n",
    "        qry_label_fg = self.compose_transformation(self.qry_label_file[idx])\n",
    "        qry_label_bg = torch.subtract(torch.ones_like(qry_label_fg),  qry_label_fg)\n",
    "\n",
    "        sample = {\"sup_img\":sup_img, \"sup_fg_label\":sup_label_fg, \"qry_img\":qry_img, \"qry_label_fg\":qry_label_fg,\n",
    "         \"sup_bg_label\":sup_label_bg, \"qry_label_bg\":qry_label_bg}\n",
    "\n",
    "        return sample\n",
    "    \n",
    "   \n",
    "\n",
    "    def compose_action(self, file_name):\n",
    "        # read data as numpy array 3d\n",
    "        data = self.nii_read_and_cut(file_name)\n",
    "        \n",
    "\n",
    "        # Add another dummpy dimention for channel as 1\n",
    "        data = data[None,:]\n",
    "        # [1,same_depth, 256,256]\n",
    "\n",
    "        # To tensor\n",
    "        data = torch.as_tensor(data,dtype=torch.double)\n",
    "\n",
    "        # Avgpool\n",
    "        # ap = nn.AvgPool3d((2, 2, 1), stride=(2, 2, 2))\n",
    "        ap = nn.AdaptiveAvgPool3d(self.adaptive_size)\n",
    "        # ap = nn.AdaptiveAvgPool3d((None,64,64))\n",
    "        data = ap(data)\n",
    "        # [1, same_depteh, 128, 128]\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "    def compose_transformation(self, file_name):\n",
    "\n",
    "        data = sitk.ReadImage(file_name)\n",
    "\n",
    "        elastic_tr = tio.RandomElasticDeformation(num_control_points=7,locked_borders=2)\n",
    "        affine_tr = tio.transforms.RandomAffine(scales=(0.5, 1.5),degrees=(10,10,10))\n",
    "        gamma_tr = tio.RandomGamma(log_gamma=(-0.3,0.3))\n",
    "\n",
    "        ts = tio.Compose([gamma_tr,affine_tr,elastic_tr])\n",
    "\n",
    "        transformed = ts(data)\n",
    "        array = sitk.GetArrayFromImage(transformed)\n",
    "        # sitk.WriteImage(transformed,\"transformed_data.nii.gz\")\n",
    "# To tensor\n",
    "        array = array[None,:]\n",
    "        data = torch.as_tensor(array,dtype=torch.double)        \n",
    "\n",
    "\n",
    "        # Avgpool\n",
    "        # ap = nn.AvgPool3d((2, 2, 1), stride=(2, 2, 2))\n",
    "        ap = nn.AdaptiveAvgPool3d(self.adaptive_size)\n",
    "        # ap = nn.AdaptiveAvgPool3d((None,64,64))\n",
    "        data = ap(data)\n",
    "        # [1, same_depteh, 128, 128]\n",
    "\n",
    "        return data\n",
    "        \n",
    "    \n",
    "    def nii_read_and_cut(self, file_name):\n",
    "\n",
    "        # numpy.array 3D\n",
    "        data = nii_read(filename=file_name)\n",
    "        # cut depth the same as same_depth\n",
    "        data = data[:self.same_depth,:,:]\n",
    "\n",
    "        return data\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import pytorch3dunet.unet3d.model as model3dUnet\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "\n",
    "class SSL3DUNet(pl.LightningModule):\n",
    "    def __init__(self,batch_size = 1, lr=1e-3):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = lr\n",
    "        # self.criterion = nn.CrossEntropyLoss()\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "        self.avgPool = nn.AdaptiveAvgPool3d((None,8,8))\n",
    "        self.thresh = .95\n",
    "        unet3d = model3dUnet.UNet3D(1,1)\n",
    "        self.unet3d = unet3d.double()\n",
    "        self.params = unet3d.parameters()\n",
    "        self.automatic_optimization = False # use own optimizer\n",
    "        self.save_hyperparameters() # for comet.ML logger\n",
    "        print(\"Finish init SSL3DUNet Model\")\n",
    "    # def forward(batch, batch_idx):\n",
    "    #     return batch \n",
    "\n",
    "    def loss(self, batch, predictions):\n",
    "\n",
    "        sup_fg_label = batch[\"sup_fg_label\"] \n",
    "        sup_bg_label = batch[\"sup_bg_label\"] \n",
    "        qry_label_fg = batch[\"qry_label_fg\"]\n",
    "        qry_label_bg = batch[\"qry_label_bg\"]\n",
    "        sup_fts = predictions[\"sup_fts\"]\n",
    "        qry_fts = predictions[\"qry_fts\"]\n",
    "\n",
    "        qry_pred, sup_pred = self._pass_compose(sup_fts, qry_fts, sup_fg_label, sup_bg_label, qry_label_fg, qry_label_bg)\n",
    "        sig = nn.Sigmoid() \n",
    "        query_loss = self.criterion(sig(qry_pred),sig(qry_label_fg))\n",
    "        experiment.log_metric(\"query_loss\", query_loss)\n",
    "        sup_loss = self.criterion(sig(sup_pred),sig(sup_fg_label))\n",
    "        experiment.log_metric(\"sup_loss\", sup_loss)\n",
    "\n",
    "        loss = torch.add(query_loss , sup_loss )\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def training_step(self,batch, batch_idx):\n",
    "        opt = self.optimizers()\n",
    "        # batch: {\"sup_img\":sup_img, \"sup_label\":sup_label, \"qry_img\":qry_img, \"qry_label\":qry_label}\n",
    "        \n",
    "        sup_img = batch[\"sup_img\"] \n",
    "        qry_img = batch[\"qry_img\"] \n",
    "        \n",
    "    #   as -> [batch, channel, 30, 128 , 128] \n",
    "    #    -> [batch, 1, 30, 128 , 128] \n",
    "\n",
    "        sup_fts = self.unet3d(sup_img) \n",
    "        qry_fts = self.unet3d(qry_img) \n",
    "        predictions = {\"sup_fts\":sup_fts, \"qry_fts\":qry_fts} \n",
    "        opt.zero_grad()\n",
    "        loss = self.loss(batch,predictions)\n",
    "        self.manual_backward(loss)\n",
    "        opt.step()\n",
    "        experiment.log_metric(\"training loss\", loss)\n",
    "        return {\"loss\":loss} \n",
    "\n",
    "    def validation_step(self,batch, batch_idx):\n",
    "        # batch: {\"sup_img\":sup_img, \"sup_label\":sup_label, \"qry_img\":qry_img, \"qry_label\":qry_label}\n",
    "        sup_img = batch[\"sup_img\"] \n",
    "        qry_img = batch[\"qry_img\"] \n",
    "    #   as -> [batch, channel, 30, 128 , 128] \n",
    "    #    -> [batch, 1, 30, 128 , 128] \n",
    "        sup_fts = self.unet3d(sup_img) \n",
    "        qry_fts = self.unet3d(qry_img) \n",
    "\n",
    "        predictions = {\"sup_fts\":sup_fts, \"qry_fts\":qry_fts} \n",
    "        loss = self.loss(batch,predictions)\n",
    "        experiment.log_metric(\"validation loss\", loss)\n",
    "        return {\"x\":loss} \n",
    "        \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.params, lr=self.learning_rate)\n",
    "        # lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=0.1)\n",
    "        return [optimizer]\n",
    "    \n",
    "    def _pass_compose(self,sup_fts, qry_fts, sup_fg_label, sup_bg_label, qry_label_fg, qry_label_bg):\n",
    "        \n",
    "        raw_score_bg = self._alp_module(qry_fts,sup_fts,sup_bg_label,mode='local',thresh=self.thresh)\n",
    "        NO_OVER_THRES =  torch.all(torch.flatten(sup_fg_label < self.thresh))\n",
    "        raw_score_fg = self._alp_module(qry_fts,sup_fts,sup_fg_label,mode='global' if not NO_OVER_THRES else 'mask',thresh=self.thresh)\n",
    "        qry_pred = torch.div(torch.add(raw_score_bg, raw_score_fg),2)\n",
    "\n",
    "        re_raw_score_bg = self._alp_module(sup_fts,qry_fts,qry_label_bg,mode='local',thresh=self.thresh)\n",
    "        RES_NO_OVER_THRES =  torch.all(torch.flatten(qry_label_fg < self.thresh))\n",
    "        re_raw_score_fg = self._alp_module(sup_fts,qry_fts,qry_label_fg,mode='global' if not RES_NO_OVER_THRES else 'mask',thresh=self.thresh)\n",
    "        sup_pred = torch.div(torch.add(re_raw_score_bg, re_raw_score_fg),2)\n",
    "\n",
    "        return qry_pred, sup_pred\n",
    "\n",
    "    def _alp_module(self, qry_fts, sup_fts, sup_label, mode='global', thresh=.95):\n",
    "    \n",
    "        # [1, same_depteh, 16, 16]\n",
    "        if mode == 'local':\n",
    "            \n",
    "            ch = qry_fts.shape[1] # temp: 64\n",
    "\n",
    "            n_sup_x = self.avgPool(sup_fts)\n",
    "            sup_nshot = sup_fts.shape[0] # 1\n",
    "\n",
    "            n_sup_x = n_sup_x.view(sup_nshot,ch,-1).permute(0,2,1).unsqueeze(0)\n",
    "            n_sup_x = n_sup_x.reshape(1,-1,ch).unsqueeze(0)\n",
    "\n",
    "            sup_y = self.avgPool(sup_label) \n",
    "            sup_y = sup_y.view(sup_nshot,1,-1)\n",
    "            sup_y = sup_y.permute(1,0,2).view(1,-1).unsqueeze(0)\n",
    "\n",
    "            pro_n = n_sup_x[sup_y > thresh,:]\n",
    "\n",
    "            qry_n = self._safe_norm(qry_fts) \n",
    "\n",
    "            dists = F.conv3d(qry_n,pro_n[...,None,None,None]) * 20\n",
    "            pred_grid =  torch.sum(F.softmax(dists,dim=1)*dists, dim=1,keepdim=True)\n",
    "            return pred_grid\n",
    "            \n",
    "        elif mode == 'global':\n",
    "            \n",
    "            ch = qry_fts.shape[1] # temp: 64\n",
    "\n",
    "            n_sup_x = self.avgPool(sup_fts)\n",
    "            sup_nshot = sup_fts.shape[0] # 1\n",
    "\n",
    "            n_sup_x = n_sup_x.view(sup_nshot,ch,-1).permute(0,2,1).unsqueeze(0)\n",
    "            n_sup_x = n_sup_x.reshape(1,-1,ch).unsqueeze(0)\n",
    "\n",
    "            sup_y = self.avgPool(sup_label) \n",
    "            sup_y = sup_y.view(sup_nshot,1,-1)\n",
    "            sup_y = sup_y.permute(1,0,2).view(1,-1).unsqueeze(0)\n",
    "\n",
    "            pro_n = n_sup_x[sup_y > thresh,:]\n",
    "\n",
    "            ##################\n",
    "            # global\n",
    "            glb_proto = torch.sum(sup_fts * sup_label, dim=(-1,-2,-3)) / (sup_label.sum(dim=(-1,-2,-3)) + 1e-5)\n",
    "            pro_n = self._safe_norm(torch.cat([pro_n, glb_proto], dim=0))\n",
    "            qry_n = self._safe_norm(qry_fts) \n",
    "            ##############\n",
    "\n",
    "            dists = F.conv3d(qry_n,pro_n[...,None,None,None]) * 20\n",
    "            pred_grid =  torch.sum(F.softmax(dists,dim=1)*dists, dim=1,keepdim=True)\n",
    "            \n",
    "            return pred_grid\n",
    "            \n",
    "        elif mode == 'mask':\n",
    "            proto = torch.sum(sup_fts * sup_label, dim=(-1,-2,-3)) / (sup_label.sum(dim=(-1,-2,-3)) + 1e-5)\n",
    "            proto = proto.mean(dim=0, keepdim=True)\n",
    "            pred_mask = F.cosine_similarity(qry_fts, proto[..., None,None], dim=1, eps=1e-4) * 20\n",
    "\n",
    "            return pred_mask.unsqueeze(1)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    def _safe_norm(self, input, p=2, dim = 1, eps = 1e-4):\n",
    "        x_norm = torch.norm(input,p=p,dim=dim)\n",
    "        x_norm = torch.max(x_norm,torch.ones_like(x_norm,requires_grad=False)*eps )\n",
    "        output = input.div(x_norm.unsqueeze(1).expand_as(input))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CometLogger will be initialized in online mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish init SSL3DUNet Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homeL/1sliu/anaconda3/envs/unet3d/lib/python3.8/site-packages/pytorch_lightning/loops/utilities.py:91: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strat trainning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name      | Type              | Params\n",
      "------------------------------------------------\n",
      "0 | criterion | BCEWithLogitsLoss | 0     \n",
      "1 | avgPool   | AdaptiveAvgPool3d | 0     \n",
      "2 | unet3d    | UNet3D            | 16.3 M\n",
      "------------------------------------------------\n",
      "16.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "16.3 M    Total params\n",
      "65.275    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homeL/1sliu/anaconda3/envs/unet3d/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1933: PossibleUserWarning: The number of training batches (8) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33:  80%|████████  | 8/10 [00:13<00:03,  1.73s/it, v_num=28] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homeL/1sliu/anaconda3/envs/unet3d/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:726: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.ml/fabzhang/ssl/eb0f4197fda54c4ba68ce0d0680f69b4\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     loss [28]            : (1.5450568718546869, 1.5959328368930477)\n",
      "COMET INFO:     query_loss [340]     : (0.7177495957098169, 0.8041142447614049)\n",
      "COMET INFO:     sup_loss [340]       : (0.7688519312905289, 0.79675026924767)\n",
      "COMET INFO:     training loss [272]  : (1.5144982914072447, 1.6008222273301902)\n",
      "COMET INFO:     validation loss [68] : (1.5522569496882097, 1.5943242798804018)\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     conda-info               : 1\n",
      "COMET INFO:     conda-specification      : 1\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (33.78 KB)\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO:     model graph              : 1\n",
      "COMET INFO:     notebook                 : 1\n",
      "COMET INFO:     os packages              : 1\n",
      "COMET INFO:     source_code              : 1\n",
      "COMET INFO: ---------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end trainning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Uploading metrics, params, and assets to Comet before program termination (may take several seconds)\n",
      "COMET INFO: The Python SDK has 3600 seconds to finish before aborting...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.utils.data import random_split,DataLoader \n",
    "import torchio.transforms as transforms \n",
    "from pytorch_lightning.loggers import CometLogger\n",
    "\n",
    "torch.manual_seed(0) # set default seed for torch operation\n",
    "dataset = SSLDataset(base_dir,sup_img_file,sup_label_file,qry_img_file,qry_label_file)\n",
    "train, val = random_split(dataset,[16,4])\n",
    "model = SSL3DUNet()\n",
    "comet_logger = CometLogger(\n",
    "    api_key=\"4e45dKB4oaj3YgKFrQ0MhPld1\",\n",
    "    rest_api_key=\"4e45dKB4oaj3YgKFrQ0MhPld1\",\n",
    "    optimizer_data=model.parameters(),\n",
    ")\n",
    "\n",
    "\n",
    "# trainer = pl.Trainer(fast_dev_run=False, accelerator='gpu',devices=[1],log_every_n_steps=10, max_epochs=10, max_steps=10,logger=[comet_logger])\n",
    "trainer = pl.Trainer(fast_dev_run=False, accelerator='gpu',devices=[0])\n",
    "train_loader = DataLoader(train,batch_size=2,num_workers=24)\n",
    "val_loader = DataLoader(val,batch_size=2,num_workers=24)\n",
    "\n",
    "print(\"strat trainning\")\n",
    "trainer.fit(model, train_loader, val_loader )\n",
    "print(\"end trainning\")\n",
    "\n",
    "experiment.end()\n",
    "######################################################################################################## STOP HERE ########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "AttributeError: partially initialized module 'ssl' has no attribute 'PROTOCOL_TLSv1' (most likely due to a circular import). \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# import torch.nn as nn\n",
    "# import torch\n",
    "# from torch.nn import functional as F\n",
    "# # pool of square window of size=3, stride=2\n",
    "# m = nn.AvgPool3d(3, stride=2)\n",
    "# # pool of non-square window\n",
    "# # m = nn.AvgPool3d((2, 2, 1), stride=(2, 2, 2))\n",
    "\n",
    "# # m = nn.AvgPool3d((4, 4, 1), stride=(1, 4, 4))\n",
    "# m = nn.AdaptiveAvgPool3d((None,128,128))\n",
    "# input = torch.randn(1, 32, 32, 32)\n",
    "# t = torch.randn( 16, 32)\n",
    "# output = F.conv2d(input, t[...,None,None])*20\n",
    "\n",
    "# # x_norm = torch.norm(input,p=2,dim=1)\n",
    "# # x_norm = torch.max(x_norm,torch.ones_like(x_norm)*1e-4 )\n",
    "# # output = input.div(x_norm.unsqueeze(1).expand_as(input))\n",
    "# # input = torch.randn(1, 1, 31,256, 256)\n",
    "# # input = torch.randn(1, 1, 15,128, 128)\n",
    "# # output = m(input)\n",
    "# #output = input.squeeze(0)\n",
    "# print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "AttributeError: partially initialized module 'ssl' has no attribute 'PROTOCOL_TLSv1' (most likely due to a circular import). \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# #\n",
    "# # 2D testing\n",
    "# # 64,15,128,128\n",
    "# # 64, 1, 1, 1 as prototype\n",
    "# #\n",
    "# import torch\n",
    "# from torch.nn import functional as F\n",
    "\n",
    "\n",
    "# def safe_norm( input, p=2, dim = 1, eps = 1e-4):\n",
    "#     x_norm = torch.norm(input,p=p,dim=dim)\n",
    "#     x_norm = torch.max(x_norm,torch.ones_like(x_norm)*eps )\n",
    "#     output = input.div(x_norm.unsqueeze(1).expand_as(input))\n",
    "#     return output\n",
    "\n",
    "\n",
    "# sup_x = torch.randn( 1,256, 32, 32)\n",
    "# sup_y = torch.randn( 1,256, 32, 32)\n",
    "# glb_proto = torch.sum(sup_x * sup_y, dim=(-1,-2)) / (sup_y.sum(dim=(-1,-2)) + 1e-5)\n",
    "# print(glb_proto.shape)\n",
    "\n",
    "\n",
    "# input = torch.randn( 1,256, 16, 16)\n",
    "# qry_n = torch.randn( 1,256, 32, 32)\n",
    "\n",
    "\n",
    "# t1 = input.view(1,256,-1).permute(0,2,1).unsqueeze(0)\n",
    "# print(input.view(1,256,-1).shape)\n",
    "# print(f\"t1.shape:{t1.shape}\")\n",
    "# t2 = t1.reshape(1,-1,256).unsqueeze(0)\n",
    "# print(f\"t2.shape:{t2.shape}\")\n",
    "\n",
    "# sup_y = torch.randn( 1,1, 16, 16)\n",
    "# print(f\"input shape:{input.shape}\")\n",
    "# y1 = sup_y.view(1,1,-1)\n",
    "# print(f\"y1 shape:{y1.shape}\")\n",
    "# y2 = y1.permute(1,0,2)\n",
    "# print(f\"y2 shape:{y2.shape}\")\n",
    "# y3 = y2.view(1,-1)\n",
    "# print(f\"y3 shpae:{y3.shape}\")\n",
    "# y4 = y3.unsqueeze(0)\n",
    "# print(f\"y4 shape:{y4.shape}\")\n",
    "\n",
    "# pro_n = t2[y4 > 0.95,:]\n",
    "# print(f\"pro_n.shape:{pro_n.shape}\")\n",
    "\n",
    "# # for global\n",
    "# pro_n = safe_norm(torch.cat([pro_n, glb_proto], dim=0))\n",
    "# print(f\"pro_n global shape:{pro_n.shape}\")\n",
    "# qry_n = safe_norm(qry_n)\n",
    "# print(f\"qry_n global shape:{qry_n.shape}\")\n",
    "\n",
    "# dists = F.conv2d(qry_n,pro_n[...,None,None]) * 20\n",
    "# print(f\"dists sahpe:{dists.shape}\")\n",
    "# pred_grid =  torch.sum(F.softmax(dists,dim=1)*dists, dim=1,keepdim=True)\n",
    "# print(f\"pred_grid.shape:{pred_grid.shape}\")\n",
    "\n",
    "# sup_pred = torch.cat([pred_grid,], dim=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "AttributeError: partially initialized module 'ssl' has no attribute 'PROTOCOL_TLSv1' (most likely due to a circular import). \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "# ch = 64\n",
    "\n",
    "# sup_x = torch.randn( 1,ch, 30, 256, 256)\n",
    "# sup_y = torch.randn( 1,ch, 30, 256, 256)\n",
    "# glb_proto = torch.sum(sup_x * sup_y, dim=(-1,-2,-3)) / (sup_y.sum(dim=(-1,-2,-3)) + 1e-5)\n",
    "# print(glb_proto.shape)\n",
    "\n",
    "# input = torch.randn( 1, ch,30, 16, 16)\n",
    "# qry_n = torch.randn( 1,ch, 30, 256, 256)\n",
    "\n",
    "\n",
    "# t1 = input.view(1,ch,-1).permute(0,2,1).unsqueeze(0)\n",
    "# print(f\"t1.shape:{t1.shape}\")\n",
    "# t2 = t1.reshape(1,-1,ch).unsqueeze(0)\n",
    "# print(f\"t2.shape:{t2.shape}\")\n",
    "\n",
    "# nb = 1\n",
    "# nshot = 1\n",
    "# sup_y = torch.randn( nshot,nb, 30, 16, 16)\n",
    "# y1 = sup_y.view(1,1,-1)\n",
    "# print(f\"y1 shape:{y1.shape}\")\n",
    "# y2 = y1.permute(1,0,2)\n",
    "# print(f\"y2 shape:{y2.shape}\")\n",
    "# y3 = y2.view(1,-1)\n",
    "# print(f\"y3 shpae:{y3.shape}\")\n",
    "# y4 = y3.unsqueeze(0)\n",
    "# print(f\"y4 shape:{y4.shape}\")\n",
    "\n",
    "# pro_n = t2[y4 > 0.95,:]\n",
    "# print(f\"pro_n.shape:{pro_n.shape}\")\n",
    "\n",
    "\n",
    "# # for global\n",
    "# pro_n = safe_norm(torch.cat([pro_n, glb_proto], dim=0))\n",
    "# print(f\"pro_n global shape:{pro_n.shape}\")\n",
    "# qry_n = safe_norm(qry_n)\n",
    "# print(f\"qry_n global shape:{qry_n.shape}\")\n",
    "\n",
    "# dists = F.conv3d(qry_n,pro_n[...,None,None,None]) * 20\n",
    "# print(f\"dists sahpe:{dists.shape}\")\n",
    "# pred_grid =  torch.sum(F.softmax(dists,dim=1)*dists, dim=1,keepdim=True)\n",
    "# print(f\"pred_grid.shape:{pred_grid.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "AttributeError: partially initialized module 'ssl' has no attribute 'PROTOCOL_TLSv1' (most likely due to a circular import). \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import torch\n",
    "# a = torch.rand(1,3,2,1)\n",
    "# print(a)\n",
    "# print(a.shape)\n",
    "# b = a.argmax(dim=1).unsqueeze(0)\n",
    "# c = [b==i for i in range(2)]\n",
    "# c[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "AttributeError: partially initialized module 'ssl' has no attribute 'PROTOCOL_TLSv1' (most likely due to a circular import). \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# # sup_x = 16*16*256\n",
    "# # BG_mask = 16*16\n",
    "# # \n",
    "# a = torch.rand(1,1,2,15,32,32)\n",
    "# a.view(-1,*a[:-4]).shape\n",
    "# a.view((1,1,1,30,32,32)).shape\n",
    "# #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "AttributeError: partially initialized module 'ssl' has no attribute 'PROTOCOL_TLSv1' (most likely due to a circular import). \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# # Declarations (dummy tensors)\n",
    "# rgb_im = torch.randint(0, 255, [1, 3, 256, 256])\n",
    "# depth = torch.randint(0, 400, [1, 1, 256, 256])\n",
    "\n",
    "# # Calculations\n",
    "# depth_ohe = F.one_hot(depth, num_classes=400)       # of shape (batch, channel, height, width, binary)\n",
    "# print(depth_ohe.shape)\n",
    "# bchwd_tensor = rgb_im.unsqueeze(-1)*depth_ohe       # of shape (batch, channel, height, width, depth)\n",
    "# print(bchwd_tensor.shape)\n",
    "# bcdhw_tensor = bchwd_tensor.permute(0, 1, 4, 2, 3)  # of shape (batch, channel, depth, height, width)\n",
    "# print(bcdhw_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "AttributeError: partially initialized module 'ssl' has no attribute 'PROTOCOL_TLSv1' (most likely due to a circular import). \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "AttributeError: partially initialized module 'ssl' has no attribute 'PROTOCOL_TLSv1' (most likely due to a circular import). \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from medpy.io import load\n",
    "import numpy\n",
    "\n",
    "# copy spacing and orientation info between sitk objects\n",
    "def copy_info(src, dst):\n",
    "    dst.SetSpacing(src.GetSpacing())\n",
    "    dst.SetOrigin(src.GetOrigin())\n",
    "    dst.SetDirection(src.GetDirection())\n",
    "    #dst.CopyInfomation(src)\n",
    "    return dst\n",
    "\n",
    "def nii_read(filename):\n",
    "    # print(f\"nii_resad:{filename}\")\n",
    "    # voxel_obj =  sitk.ReadImage(filename)\n",
    "    # print(voxel_obj)\n",
    "    # voxel_arr = sitk.GetArrayFromImage(voxel_obj) \n",
    "    # print(voxel_arr.shape)\n",
    "    voxel_arr,voxel_header = load(filename)\n",
    "    voxel_arr = numpy.swapaxes(voxel_arr,0,2)\n",
    "    return voxel_arr\n",
    "    \n",
    "def nii_read_and_cut(file_name):\n",
    "\n",
    "# numpy.array 3D\n",
    "    data = nii_read(filename=file_name)\n",
    "# cut depth the same as same_depth\n",
    "    data = data[:30,:,:]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "AttributeError: partially initialized module 'ssl' has no attribute 'PROTOCOL_TLSv1' (most likely due to a circular import). \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torchio as tio\n",
    "import os\n",
    "import SimpleITK as sitk\n",
    "import nibabel as nib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "elastic_tr = tio.RandomElasticDeformation(\n",
    "    num_control_points=7,\n",
    "    locked_borders=2,\n",
    ")\n",
    "affine_tr = tio.transforms.RandomAffine(\n",
    "    scales=(0.5, 1.5),\n",
    "    degrees=(10,10,10),\n",
    ")\n",
    "gamma_tr = tio.RandomGamma(\n",
    "    log_gamma=(-0.3,0.3)\n",
    ")\n",
    "\n",
    "ts = tio.Compose([\n",
    "    gamma_tr,\n",
    "    affine_tr,\n",
    "    elastic_tr,\n",
    "])\n",
    "\n",
    "img_path = './data/CHAOST2/chaos_MR_T2_normalized'\n",
    "img = 'image_1.nii.gz'\n",
    "file_name = os.path.join(img_path,img)\n",
    "print(file_name)\n",
    "# data = nii_read_and_cut(file_name)\n",
    "data = sitk.ReadImage(file_name)\n",
    "print(type(data))\n",
    "# print(data.shape)\n",
    "# data = data[None,:]\n",
    "transformed = ts(data)\n",
    "array = sitk.GetArrayFromImage(transformed)\n",
    "print(array.shape)\n",
    "print(type(array))\n",
    "# print(transformed.shape)\n",
    "# data = numpy.squeeze(data,axis=0)\n",
    "# data = numpy.swapaxes(data, 0,2)\n",
    "# data_img = nib.Nifti1Image(data,numpy.eye(4))\n",
    "# nib.save(data_img, \"transformed_data.nii.gz\")\n",
    "sitk.WriteImage(transformed,\"transformed_data.nii.gz\")\n",
    "# To tensor\n",
    "array = array[None,:]\n",
    "data = torch.as_tensor(array,dtype=torch.double)\n",
    "\n",
    "# Avgpool\n",
    "# ap = nn.AvgPool3d((2, 2, 1), stride=(2, 2, 2))\n",
    "ap = nn.AdaptiveAvgPool3d((30,32,32))\n",
    "# ap = nn.AdaptiveAvgPool3d((None,64,64))\n",
    "data = ap(data)\n",
    "data = data.detach().numpy()\n",
    "data = numpy.squeeze(data,axis=0)\n",
    "data_img = nib.Nifti1Image(data,numpy.eye(4))\n",
    "nib.save(data_img, \"transformed_data_Pool.nii.gz\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "AttributeError: partially initialized module 'ssl' has no attribute 'PROTOCOL_TLSv1' (most likely due to a circular import). \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "def compose_transformation(self, file_name):\n",
    "\n",
    "        #if label -> no gamma transform (does it even make a difference?)\n",
    "        # read data as numpy array 3d\n",
    "        data = self.nii_read_and_cut(file_name)\n",
    "        \n",
    "\n",
    "        # Add another dummpy dimention for channel as 1\n",
    "        data = data[None,:]\n",
    "        # [1,same_depth, 256,256]\n",
    "\n",
    "        # To tensor\n",
    "        #data = torch.as_tensor(data,dtype=torch.double)\n",
    "        #TO NII\n",
    "\n",
    "        elastic_tr = tio.RandomElasticDeformation(num_control_points=7,locked_borders=2)\n",
    "        affine_tr = tio.transforms.RandomAffine(scales=(0.5, 1.5),degrees=(10,10,10))\n",
    "        gamma_tr = tio.RandomGamma(log_gamma=(-0.3,0.3))\n",
    "\n",
    "        ts = tio.Compose([gamma_tr,affine_tr,elastic_tr])\n",
    "\n",
    "        transformed = ts(data)\n",
    "        array = sitk.GetArrayFromImage(transformed)\n",
    "        sitk.WriteImage(transformed,\"transformed_data.nii.gz\")\n",
    "# To tensor\n",
    "        array = array[None,:]\n",
    "        data = torch.as_tensor(array,dtype=torch.double)        \n",
    "\n",
    "\n",
    "        # Avgpool\n",
    "        # ap = nn.AvgPool3d((2, 2, 1), stride=(2, 2, 2))\n",
    "        ap = nn.AdaptiveAvgPool3d((15,32,32))\n",
    "        # ap = nn.AdaptiveAvgPool3d((None,64,64))\n",
    "        data = ap(data)\n",
    "        # [1, same_depteh, 128, 128]\n",
    "\n",
    "        return data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('unet3d')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05f2d1a0c395dbcbe4c9360e9d03ffb3e8b47f17932c57d7b4eaccbd70357b44"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
